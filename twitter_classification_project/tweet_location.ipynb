{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Tweets\n",
    "\n",
    "THIS WILL USE THE FOLLOWING DATA `new_york.json`, `london.json`, and `paris.json`. These three files contain tweets that we gathered from those locations.\n",
    "\n",
    "The goal is to create a classification algorithm that can classify any tweet (or sentence) and predict whether that sentence came from New York, London, or Paris."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](download.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4723\n",
      "\n",
      "Index(['created_at', 'id', 'id_str', 'text', 'display_text_range', 'source',\n",
      "       'truncated', 'in_reply_to_status_id', 'in_reply_to_status_id_str',\n",
      "       'in_reply_to_user_id', 'in_reply_to_user_id_str',\n",
      "       'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place',\n",
      "       'contributors', 'is_quote_status', 'quote_count', 'reply_count',\n",
      "       'retweet_count', 'favorite_count', 'entities', 'favorited', 'retweeted',\n",
      "       'filter_level', 'lang', 'timestamp_ms', 'extended_tweet',\n",
      "       'possibly_sensitive', 'quoted_status_id', 'quoted_status_id_str',\n",
      "       'quoted_status', 'quoted_status_permalink', 'extended_entities',\n",
      "       'withheld_in_countries'],\n",
      "      dtype='object')\n",
      "\n",
      "Be best #ThursdayThoughts\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>text</th>\n",
       "      <th>display_text_range</th>\n",
       "      <th>source</th>\n",
       "      <th>truncated</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>...</th>\n",
       "      <th>lang</th>\n",
       "      <th>timestamp_ms</th>\n",
       "      <th>extended_tweet</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>quoted_status</th>\n",
       "      <th>quoted_status_permalink</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>withheld_in_countries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-07-26 13:32:33+00:00</td>\n",
       "      <td>1022474755625164800</td>\n",
       "      <td>1022474755625164800</td>\n",
       "      <td>@DelgadoforNY19 Calendar marked.</td>\n",
       "      <td>[16, 32]</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.022208e+18</td>\n",
       "      <td>1.022208e+18</td>\n",
       "      <td>8.290618e+17</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>2018-07-26 13:32:33.060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-26 13:32:34+00:00</td>\n",
       "      <td>1022474762491183104</td>\n",
       "      <td>1022474762491183104</td>\n",
       "      <td>petition to ban more than one spritz of cologne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>2018-07-26 13:32:34.697</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-07-26 13:32:35+00:00</td>\n",
       "      <td>1022474765750226945</td>\n",
       "      <td>1022474765750226944</td>\n",
       "      <td>People really be making up beef with you in th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>2018-07-26 13:32:35.474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 created_at                   id               id_str  \\\n",
       "0 2018-07-26 13:32:33+00:00  1022474755625164800  1022474755625164800   \n",
       "1 2018-07-26 13:32:34+00:00  1022474762491183104  1022474762491183104   \n",
       "2 2018-07-26 13:32:35+00:00  1022474765750226945  1022474765750226944   \n",
       "\n",
       "                                                text display_text_range  \\\n",
       "0                   @DelgadoforNY19 Calendar marked.           [16, 32]   \n",
       "1    petition to ban more than one spritz of cologne                NaN   \n",
       "2  People really be making up beef with you in th...                NaN   \n",
       "\n",
       "                                              source  truncated  \\\n",
       "0  <a href=\"http://twitter.com/download/android\" ...      False   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...      False   \n",
       "2  <a href=\"http://twitter.com/download/iphone\" r...      False   \n",
       "\n",
       "   in_reply_to_status_id  in_reply_to_status_id_str  in_reply_to_user_id  ...  \\\n",
       "0           1.022208e+18               1.022208e+18         8.290618e+17  ...   \n",
       "1                    NaN                        NaN                  NaN  ...   \n",
       "2                    NaN                        NaN                  NaN  ...   \n",
       "\n",
       "   lang            timestamp_ms extended_tweet possibly_sensitive  \\\n",
       "0    en 2018-07-26 13:32:33.060            NaN                NaN   \n",
       "1    en 2018-07-26 13:32:34.697            NaN                NaN   \n",
       "2    en 2018-07-26 13:32:35.474            NaN                NaN   \n",
       "\n",
       "  quoted_status_id quoted_status_id_str  quoted_status  \\\n",
       "0              NaN                  NaN            NaN   \n",
       "1              NaN                  NaN            NaN   \n",
       "2              NaN                  NaN            NaN   \n",
       "\n",
       "   quoted_status_permalink  extended_entities  withheld_in_countries  \n",
       "0                      NaN                NaN                    NaN  \n",
       "1                      NaN                NaN                    NaN  \n",
       "2                      NaN                NaN                    NaN  \n",
       "\n",
       "[3 rows x 36 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "new_york_tweets = pd.read_json(\"new_york.json\", lines=True)\n",
    "print(len(new_york_tweets))\n",
    "print()\n",
    "print(new_york_tweets.columns)\n",
    "print()\n",
    "print(new_york_tweets.loc[12][\"text\"])\n",
    "print()\n",
    "new_york_tweets.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The number of tweets.\n",
    "* The columns, or features, of a tweet.\n",
    "* The text of the 12th tweet in the New York dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5341\n",
      "2510\n"
     ]
    }
   ],
   "source": [
    "london_tweets = pd.read_json(\"london.json\", lines=True)\n",
    "paris_tweets = pd.read_json(\"paris.json\", lines=True)\n",
    "print(len(london_tweets))\n",
    "print(len(paris_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying using language: Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_york_text = new_york_tweets[\"text\"].tolist()\n",
    "london_text = london_tweets[\"text\"].tolist()\n",
    "paris_text = paris_tweets[\"text\"].tolist()\n",
    "\n",
    "all_tweets = new_york_text + london_text + paris_text\n",
    "labels = [0] * len(new_york_text) + [1] * len(london_text) + [2] * len(paris_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a Training and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10059 2515\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(all_tweets, labels, test_size = 0.2, random_state = 1)\n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the Count Vectors\n",
    "\n",
    "To use a Naive Bayes Classifier, we need to transform our lists of words into count vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saying bye is hard. Especially when youre saying bye to comfort.\n",
      "\n",
      "  (0, 5022)\t2\n",
      "  (0, 6371)\t1\n",
      "  (0, 9552)\t1\n",
      "  (0, 12314)\t1\n",
      "  (0, 13903)\t1\n",
      "  (0, 23994)\t2\n",
      "  (0, 27146)\t1\n",
      "  (0, 29397)\t1\n",
      "  (0, 30274)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "counter = CountVectorizer()\n",
    "\n",
    "\n",
    "counter.fit(train_data)\n",
    "\n",
    "\n",
    "train_counts = counter.transform(train_data)\n",
    "test_counts = counter.transform(test_data)\n",
    "\n",
    "\n",
    "print(train_data[3])\n",
    "print()\n",
    "print(train_counts[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test the Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(train_counts, train_labels)\n",
    "predictions = classifier.predict(test_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6779324055666004\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[541 404  28]\n",
      " [203 824  34]\n",
      " [ 38 103 340]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Your Own Tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict where my tweet is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TWEET 1\n",
    "Times Square is preparing for Phase 2 of reopening in NYC. Tables are appropriately distanced with 2 chairs per table and are being regularly cleaned by the Times Square Alliance Sanitation team (pictured: Lisa Ringgold, Supervisor, and Herbert Murray, Assistant Supervisor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TWEET 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pastel pink skies over iconic London scenes Destellos What have you been revisiting since the easing of lockdown? Let us know belowDorso de la mano con el dedo Ã­ndice seÃ±alando hacia abajo #BecauseImALondoner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TWEET 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boire rÃ©guliÃ¨rement de l'eau, Ã©viter les efforts physiques, maintenir son appartement au frais...  Pendant la #canicule, adoptez les bons rÃ©flexes !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New york                   |  london                   |    Paris                |\n",
    ":-------------------------:|:-------------------------:|:-----------------------:|\n",
    "![](tweet1.png)            |  ![](tweet2.png)          |  ![](tweet3.png)        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[1]\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "tweet = \"Times Square is preparing for Phase 2 of reopening in NYC. Tables are appropriately distanced with 2 chairs per table and are being regularly cleaned by the Times Square Alliance Sanitation team (pictured: Lisa Ringgold, Supervisor, and Herbert Murray, Assistant Supervisor\"\n",
    "\n",
    "tweet_counts = counter.transform([tweet])\n",
    "result1 = classifier.predict(tweet_counts)\n",
    "print(result1)\n",
    "\n",
    "tweet2 = \"Pastel pink skies over iconic London scenes Destellos What have you been revisiting since the easing of lockdown? Let us know belowDorso de la mano con el dedo Ã­ndice seÃ±alando hacia abajo #BecauseImALondoner\"\n",
    "\n",
    "tweet_counts = counter.transform([tweet2])\n",
    "result2 = classifier.predict(tweet_counts)\n",
    "print(result2)\n",
    "\n",
    "\n",
    "tweet3 = \"Boire rÃ©guliÃ¨rement de l'eau, Ã©viter les efforts physiques, maintenir son appartement au frais...  Pendant la #canicule, adoptez les bons rÃ©flexes !\"\n",
    "\n",
    "tweet_counts = counter.transform([tweet3])\n",
    "result3 = classifier.predict(tweet_counts)\n",
    "print(result3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[0] -> new york\n",
    "\n",
    "[1] -> London\n",
    "\n",
    "[2] -> paris"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
