{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Tweets\n",
    "\n",
    "THIS WILL USE THE FOLLOWING DATA `new_york.json`, `london.json`, and `paris.json`. These three files contain tweets that we gathered from those locations.\n",
    "\n",
    "The goal is to create a classification algorithm that can classify any tweet (or sentence) and predict whether that sentence came from New York, London, or Paris."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](download.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4723\n",
      "\n",
      "Index(['created_at', 'id', 'id_str', 'text', 'display_text_range', 'source',\n",
      "       'truncated', 'in_reply_to_status_id', 'in_reply_to_status_id_str',\n",
      "       'in_reply_to_user_id', 'in_reply_to_user_id_str',\n",
      "       'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place',\n",
      "       'contributors', 'is_quote_status', 'quote_count', 'reply_count',\n",
      "       'retweet_count', 'favorite_count', 'entities', 'favorited', 'retweeted',\n",
      "       'filter_level', 'lang', 'timestamp_ms', 'extended_tweet',\n",
      "       'possibly_sensitive', 'quoted_status_id', 'quoted_status_id_str',\n",
      "       'quoted_status', 'quoted_status_permalink', 'extended_entities',\n",
      "       'withheld_in_countries'],\n",
      "      dtype='object')\n",
      "\n",
      "Be best #ThursdayThoughts\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>text</th>\n",
       "      <th>display_text_range</th>\n",
       "      <th>source</th>\n",
       "      <th>truncated</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>...</th>\n",
       "      <th>lang</th>\n",
       "      <th>timestamp_ms</th>\n",
       "      <th>extended_tweet</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>quoted_status</th>\n",
       "      <th>quoted_status_permalink</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>withheld_in_countries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-07-26 13:32:33+00:00</td>\n",
       "      <td>1022474755625164800</td>\n",
       "      <td>1022474755625164800</td>\n",
       "      <td>@DelgadoforNY19 Calendar marked.</td>\n",
       "      <td>[16, 32]</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.022208e+18</td>\n",
       "      <td>1.022208e+18</td>\n",
       "      <td>8.290618e+17</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>2018-07-26 13:32:33.060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-26 13:32:34+00:00</td>\n",
       "      <td>1022474762491183104</td>\n",
       "      <td>1022474762491183104</td>\n",
       "      <td>petition to ban more than one spritz of cologne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>2018-07-26 13:32:34.697</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-07-26 13:32:35+00:00</td>\n",
       "      <td>1022474765750226945</td>\n",
       "      <td>1022474765750226944</td>\n",
       "      <td>People really be making up beef with you in th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>2018-07-26 13:32:35.474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 created_at                   id               id_str  \\\n",
       "0 2018-07-26 13:32:33+00:00  1022474755625164800  1022474755625164800   \n",
       "1 2018-07-26 13:32:34+00:00  1022474762491183104  1022474762491183104   \n",
       "2 2018-07-26 13:32:35+00:00  1022474765750226945  1022474765750226944   \n",
       "\n",
       "                                                text display_text_range  \\\n",
       "0                   @DelgadoforNY19 Calendar marked.           [16, 32]   \n",
       "1    petition to ban more than one spritz of cologne                NaN   \n",
       "2  People really be making up beef with you in th...                NaN   \n",
       "\n",
       "                                              source  truncated  \\\n",
       "0  <a href=\"http://twitter.com/download/android\" ...      False   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...      False   \n",
       "2  <a href=\"http://twitter.com/download/iphone\" r...      False   \n",
       "\n",
       "   in_reply_to_status_id  in_reply_to_status_id_str  in_reply_to_user_id  ...  \\\n",
       "0           1.022208e+18               1.022208e+18         8.290618e+17  ...   \n",
       "1                    NaN                        NaN                  NaN  ...   \n",
       "2                    NaN                        NaN                  NaN  ...   \n",
       "\n",
       "   lang            timestamp_ms extended_tweet possibly_sensitive  \\\n",
       "0    en 2018-07-26 13:32:33.060            NaN                NaN   \n",
       "1    en 2018-07-26 13:32:34.697            NaN                NaN   \n",
       "2    en 2018-07-26 13:32:35.474            NaN                NaN   \n",
       "\n",
       "  quoted_status_id quoted_status_id_str  quoted_status  \\\n",
       "0              NaN                  NaN            NaN   \n",
       "1              NaN                  NaN            NaN   \n",
       "2              NaN                  NaN            NaN   \n",
       "\n",
       "   quoted_status_permalink  extended_entities  withheld_in_countries  \n",
       "0                      NaN                NaN                    NaN  \n",
       "1                      NaN                NaN                    NaN  \n",
       "2                      NaN                NaN                    NaN  \n",
       "\n",
       "[3 rows x 36 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "new_york_tweets = pd.read_json(\"new_york.json\", lines=True)\n",
    "print(len(new_york_tweets))\n",
    "print()\n",
    "print(new_york_tweets.columns)\n",
    "print()\n",
    "print(new_york_tweets.loc[12][\"text\"])\n",
    "print()\n",
    "new_york_tweets.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The number of tweets.\n",
    "* The columns, or features, of a tweet.\n",
    "* The text of the 12th tweet in the New York dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5341\n",
      "2510\n"
     ]
    }
   ],
   "source": [
    "london_tweets = pd.read_json(\"london.json\", lines=True)\n",
    "paris_tweets = pd.read_json(\"paris.json\", lines=True)\n",
    "print(len(london_tweets))\n",
    "print(len(paris_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying using language: Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_york_text = new_york_tweets[\"text\"].tolist()\n",
    "london_text = london_tweets[\"text\"].tolist()\n",
    "paris_text = paris_tweets[\"text\"].tolist()\n",
    "\n",
    "all_tweets = new_york_text + london_text + paris_text\n",
    "labels = [0] * len(new_york_text) + [1] * len(london_text) + [2] * len(paris_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a Training and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10059 2515\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(all_tweets, labels, test_size = 0.2, random_state = 1)\n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the Count Vectors\n",
    "\n",
    "To use a Naive Bayes Classifier, we need to transform our lists of words into count vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saying bye is hard. Especially when youre saying bye to comfort.\n",
      "\n",
      "  (0, 5022)\t2\n",
      "  (0, 6371)\t1\n",
      "  (0, 9552)\t1\n",
      "  (0, 12314)\t1\n",
      "  (0, 13903)\t1\n",
      "  (0, 23994)\t2\n",
      "  (0, 27146)\t1\n",
      "  (0, 29397)\t1\n",
      "  (0, 30274)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "counter = CountVectorizer()\n",
    "\n",
    "\n",
    "counter.fit(train_data)\n",
    "\n",
    "\n",
    "train_counts = counter.transform(train_data)\n",
    "test_counts = counter.transform(test_data)\n",
    "\n",
    "\n",
    "print(train_data[3])\n",
    "print()\n",
    "print(train_counts[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test the Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(train_counts, train_labels)\n",
    "predictions = classifier.predict(test_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6779324055666004\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[541 404  28]\n",
      " [203 824  34]\n",
      " [ 38 103 340]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Your Own Tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict where my tweet is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TWEET 1\n",
    "Times Square is preparing for Phase 2 of reopening in NYC. Tables are appropriately distanced with 2 chairs per table and are being regularly cleaned by the Times Square Alliance Sanitation team (pictured: Lisa Ringgold, Supervisor, and Herbert Murray, Assistant Supervisor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TWEET 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pastel pink skies over iconic London scenes Destellos What have you been revisiting since the easing of lockdown? Let us know belowDorso de la mano con el dedo índice señalando hacia abajo #BecauseImALondoner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TWEET 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boire régulièrement de l'eau, éviter les efforts physiques, maintenir son appartement au frais...  Pendant la #canicule, adoptez les bons réflexes !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New york                   |  london                   |    Paris                |\n",
    ":-------------------------:|:-------------------------:|:-----------------------:|\n",
    "![](tweet1.png)            |  ![](tweet2.png)          |  ![](tweet3.png)        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[1]\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "tweet = \"Times Square is preparing for Phase 2 of reopening in NYC. Tables are appropriately distanced with 2 chairs per table and are being regularly cleaned by the Times Square Alliance Sanitation team (pictured: Lisa Ringgold, Supervisor, and Herbert Murray, Assistant Supervisor\"\n",
    "\n",
    "tweet_counts = counter.transform([tweet])\n",
    "result1 = classifier.predict(tweet_counts)\n",
    "print(result1)\n",
    "\n",
    "tweet2 = \"Pastel pink skies over iconic London scenes Destellos What have you been revisiting since the easing of lockdown? Let us know belowDorso de la mano con el dedo índice señalando hacia abajo #BecauseImALondoner\"\n",
    "\n",
    "tweet_counts = counter.transform([tweet2])\n",
    "result2 = classifier.predict(tweet_counts)\n",
    "print(result2)\n",
    "\n",
    "\n",
    "tweet3 = \"Boire régulièrement de l'eau, éviter les efforts physiques, maintenir son appartement au frais...  Pendant la #canicule, adoptez les bons réflexes !\"\n",
    "\n",
    "tweet_counts = counter.transform([tweet3])\n",
    "result3 = classifier.predict(tweet_counts)\n",
    "print(result3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[0] -> new york\n",
    "\n",
    "[1] -> London\n",
    "\n",
    "[2] -> paris"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
